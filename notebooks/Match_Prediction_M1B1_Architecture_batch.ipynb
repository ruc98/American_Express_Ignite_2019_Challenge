{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_sequence,pad_packed_sequence,pad_sequence\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and process data\n",
    "path = r'odi_csv/'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "shuffle(all_files)\n",
    "innings2 = []\n",
    "target=[]\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename,usecols=[0])\n",
    "    skips = df.loc[ 'info' , : ].shape[0]\n",
    "\n",
    "    df = pd.read_csv(filename,nrows=skips,skiprows=1,header=None)\n",
    "    df = df.drop(columns=0).set_index(df.columns[1])\n",
    "    winteam=None\n",
    "    if 'winner' in df.index:\n",
    "        winteam = df.loc['winner',:].values[0]\n",
    "    \n",
    "    df = pd.read_csv(filename,skiprows=skips+1,header=None)\n",
    "    \n",
    "    df2 = df[df.columns[[1,2,7,8]]].set_index(df.columns[1]).drop(index=1)\n",
    "    if df2.shape[0]>0:\n",
    "        innings2.append(df2)\n",
    "        i2team = df[df.columns[[1,3]]].set_index(df.columns[1]).drop(index=1).values[0,0]\n",
    "        if (i2team==winteam):\n",
    "            target.append(1)\n",
    "        else:\n",
    "            target.append(0)\n",
    "\n",
    "# len(innings2) = 1556\n",
    "split = int(len(innings2) * 0.8)\n",
    "innings2_train=innings2[:split]\n",
    "innings2_test =innings2[split:]\n",
    "target_train  =target[:split]\n",
    "target_test   =target[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Sample generator\n",
    "def X_train_generator(ing):\n",
    "    features=[]\n",
    "    # create targets first\n",
    "    for i in range(len(ing)):\n",
    "        balls = ing[i].shape[0]\n",
    "        if balls>250:\n",
    "            j = np.random.choice(np.arange(250,balls+1))\n",
    "            features.append(torch.tensor(ing[i].values[:j]))\n",
    "        else:\n",
    "            features.append(torch.tensor(ing[i].values))\n",
    "\n",
    "    # convert to fixed length sequence\n",
    "    features,_ = pad_packed_sequence(pack_sequence(features,enforce_sorted = False), batch_first=True, padding_value=-1, total_length=321)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # All overs generator\n",
    "# def X_train_generator(ing):\n",
    "#     features=[]\n",
    "#     # create targets first\n",
    "#     for i in range(len(ing)):\n",
    "#         features.append(torch.tensor(ing[i].values))\n",
    "\n",
    "#     # convert to fixed length sequence\n",
    "#     features,_ = pad_packed_sequence(pack_sequence(features,enforce_sorted = False), batch_first=True,padding_value=-1, total_length=321)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[]\n",
    "# create targets first\n",
    "for i in range(len(innings2_test)):\n",
    "    features.append(torch.tensor(innings2_test[i].values))\n",
    "\n",
    "# convert to fixed length sequence\n",
    "X_test, _ = pad_packed_sequence(pack_sequence(features,enforce_sorted = False), batch_first=True,padding_value=-1, total_length=321)\n",
    "y_train = torch.tensor(target_train)\n",
    "y_test = torch.tensor(target_test)\n",
    "print(X_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "class matchRNN(nn.Module):\n",
    "    def __init__(self,insize,hsize,outsize):\n",
    "        super(matchRNN,self).__init__()\n",
    "        \n",
    "        self.insize=insize\n",
    "        self.hsize=hsize\n",
    "        self.outsize = outsize\n",
    "        \n",
    "        # lstm cell\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=insize, hidden_size=hsize)\n",
    "        self.fc_out = nn.Linear(in_features=hsize, out_features=outsize)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,feat):\n",
    "#         feat = torch.tensor(feat[np.newaxis,:],dtype=torch.float32)\n",
    "        batch_size = feat.size(0)\n",
    "        \n",
    "        # init the hidden and cell states to zeros\n",
    "        hidden_state = torch.zeros((batch_size, self.hsize))\n",
    "        cell_state = torch.zeros((batch_size, self.hsize))\n",
    "        for t in range(feat.size(1)):\n",
    "            hidden_state, cell_state = self.lstm_cell(feat[:,t,:].view(batch_size,-1).float(), (hidden_state, cell_state))\n",
    "\n",
    "        out = self.fc_out(hidden_state)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def X_generator(ing,j):\n",
    "    features=[]\n",
    "    # create targets first\n",
    "    for i in range(len(ing)):\n",
    "        features.append(torch.tensor(ing[i].values[:j]))\n",
    "\n",
    "    # convert to fixed length sequence\n",
    "    features,_ = pad_packed_sequence(pack_sequence(features,enforce_sorted = False), batch_first=True,padding_value=-1, total_length=321)\n",
    "    return features\n",
    "\n",
    "def evalfunc(model,j):\n",
    "    global innings2_train,innings2_test,y_train,y_test,batch_size\n",
    "    model.eval()\n",
    "    # train\n",
    "    X = X_generator(innings2_train,j)\n",
    "    y = y_train\n",
    "    corr=0\n",
    "    num_batches = X.size(0) // batch_size\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        op = model(X[start_idx:end_idx])\n",
    "        maxval,maxidx = torch.max(op,1)\n",
    "        corr+= np.sum((maxidx==y[start_idx:end_idx]).numpy())\n",
    "    total=num_batches*batch_size\n",
    "    train_acc = corr / total\n",
    "    \n",
    "    # test\n",
    "    X = X_generator(innings2_test,j)\n",
    "    y = y_test\n",
    "    corr=0\n",
    "    num_batches = X.size(0) // batch_size\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        op = model(X[start_idx:end_idx])\n",
    "        maxval,maxidx = torch.max(op,1)\n",
    "        corr+= np.sum((maxidx==y[start_idx:end_idx]).numpy())\n",
    "    total=num_batches*batch_size\n",
    "    test_acc = corr / total\n",
    "    print('j = {}, Train Acc = {}, Test Acc = {}'.format(j,train_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, loss = 53.54995155334473\n",
      "j = 321, Train Acc = 0.49594155844155846, Test Acc = 0.48026315789473684\n",
      "j = 250, Train Acc = 0.4967532467532468, Test Acc = 0.48355263157894735\n",
      "j = 200, Train Acc = 0.4967532467532468, Test Acc = 0.48355263157894735\n",
      "Epoch = 1, loss = 53.55238860845566\n",
      "Epoch = 2, loss = 53.500824213027954\n",
      "Epoch = 3, loss = 53.478012800216675\n",
      "Epoch = 4, loss = 53.31806284189224\n",
      "Epoch = 5, loss = 53.507573902606964\n",
      "Epoch = 6, loss = 53.11656981706619\n",
      "Epoch = 7, loss = 53.27751964330673\n",
      "Epoch = 8, loss = 53.45483046770096\n",
      "Epoch = 9, loss = 53.403779685497284\n",
      "Epoch = 10, loss = 53.153639793395996\n",
      "j = 321, Train Acc = 0.5381493506493507, Test Acc = 0.5230263157894737\n",
      "j = 250, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 11, loss = 53.10060238838196\n",
      "Epoch = 12, loss = 53.39316636323929\n",
      "Epoch = 13, loss = 53.37317854166031\n",
      "Epoch = 14, loss = 53.2958744764328\n",
      "Epoch = 15, loss = 53.235539615154266\n",
      "Epoch = 16, loss = 53.3509127497673\n",
      "Epoch = 17, loss = 53.17457401752472\n",
      "Epoch = 18, loss = 53.09845840930939\n",
      "Epoch = 19, loss = 53.1758331656456\n",
      "Epoch = 20, loss = 53.359767854213715\n",
      "j = 321, Train Acc = 0.538961038961039, Test Acc = 0.5197368421052632\n",
      "j = 250, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 21, loss = 53.369822323322296\n",
      "Epoch = 22, loss = 53.14697962999344\n",
      "Epoch = 23, loss = 53.197775304317474\n",
      "Epoch = 24, loss = 53.165489971637726\n",
      "Epoch = 25, loss = 52.9684374332428\n",
      "Epoch = 26, loss = 53.25115215778351\n",
      "Epoch = 27, loss = 53.163403034210205\n",
      "Epoch = 28, loss = 53.371225476264954\n",
      "Epoch = 29, loss = 53.16363829374313\n",
      "Epoch = 30, loss = 52.66990089416504\n",
      "j = 321, Train Acc = 0.5625, Test Acc = 0.4901315789473684\n",
      "j = 250, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 31, loss = 53.1704478263855\n",
      "Epoch = 32, loss = 52.63864904642105\n",
      "Epoch = 33, loss = 52.486272275447845\n",
      "Epoch = 34, loss = 52.292737782001495\n",
      "Epoch = 35, loss = 52.66933065652847\n",
      "Epoch = 36, loss = 52.274114549160004\n",
      "Epoch = 37, loss = 52.44353771209717\n",
      "Epoch = 38, loss = 52.54357451200485\n",
      "Epoch = 39, loss = 52.4655020236969\n",
      "Epoch = 40, loss = 52.457881689071655\n",
      "j = 321, Train Acc = 0.5706168831168831, Test Acc = 0.4967105263157895\n",
      "j = 250, Train Acc = 0.5706168831168831, Test Acc = 0.4967105263157895\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 41, loss = 52.41330128908157\n",
      "Epoch = 42, loss = 52.30634045600891\n",
      "Epoch = 43, loss = 52.34524363279343\n",
      "Epoch = 44, loss = 52.45367407798767\n",
      "Epoch = 45, loss = 52.342899203300476\n",
      "Epoch = 46, loss = 52.34320533275604\n",
      "Epoch = 47, loss = 52.36990249156952\n",
      "Epoch = 48, loss = 52.30440044403076\n",
      "Epoch = 49, loss = 52.26460725069046\n",
      "Epoch = 50, loss = 52.312824964523315\n",
      "j = 321, Train Acc = 0.573051948051948, Test Acc = 0.4901315789473684\n",
      "j = 250, Train Acc = 0.573051948051948, Test Acc = 0.4901315789473684\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 51, loss = 52.48326939344406\n",
      "Epoch = 52, loss = 52.340865790843964\n",
      "Epoch = 53, loss = 52.404034316539764\n",
      "Epoch = 54, loss = 52.3295413851738\n",
      "Epoch = 55, loss = 52.25100827217102\n",
      "Epoch = 56, loss = 52.306185364723206\n",
      "Epoch = 57, loss = 52.2964004278183\n",
      "Epoch = 58, loss = 52.3003756403923\n",
      "Epoch = 59, loss = 52.30981159210205\n",
      "Epoch = 60, loss = 52.21635311841965\n",
      "j = 321, Train Acc = 0.5746753246753247, Test Acc = 0.4868421052631579\n",
      "j = 250, Train Acc = 0.5746753246753247, Test Acc = 0.4868421052631579\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "\n",
    "insize=X_test.size(2)\n",
    "hsize=64\n",
    "outsize=2    #binary classification\n",
    "model = matchRNN(insize,hsize,outsize)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# train iterations\n",
    "for epoch in range(61):\n",
    "    epoch_loss=0\n",
    "    X_train = X_train_generator(innings2_train)\n",
    "    num_batches = X_train.size(0) // batch_size\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        model.zero_grad()\n",
    "        op = model(X_train[start_idx:end_idx])\n",
    "        loss = loss_function(op.contiguous().view(-1,outsize), y_train[start_idx:end_idx].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss+=loss.data.item()\n",
    "        optimizer.step()\n",
    "    print('Epoch = {}, loss = {}'.format(epoch,epoch_loss))\n",
    "    if epoch%10==0:\n",
    "        for j in [321,250,200]:\n",
    "            evalfunc(model,j)\n",
    "\n",
    "torch.save(model.state_dict(), './models/cric_prediction_M1B1_randomsample.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 61, loss = 52.29833424091339\n",
      "Epoch = 62, loss = 52.21452534198761\n",
      "Epoch = 63, loss = 51.61600208282471\n",
      "Epoch = 64, loss = 51.97134047746658\n",
      "Epoch = 65, loss = 51.952072739601135\n",
      "Epoch = 66, loss = 51.27543890476227\n",
      "Epoch = 67, loss = 50.14579477906227\n",
      "Epoch = 68, loss = 48.916630417108536\n",
      "Epoch = 69, loss = 52.01295745372772\n",
      "Epoch = 70, loss = 52.61844131350517\n",
      "j = 321, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "j = 250, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "j = 200, Train Acc = 0.5422077922077922, Test Acc = 0.5460526315789473\n",
      "Epoch = 71, loss = 50.26707103848457\n",
      "Epoch = 72, loss = 49.369433373212814\n",
      "Epoch = 73, loss = 47.90370932221413\n",
      "Epoch = 74, loss = 46.723154067993164\n",
      "Epoch = 75, loss = 45.69775667786598\n",
      "Epoch = 76, loss = 47.40668934583664\n",
      "Epoch = 77, loss = 47.15504705905914\n",
      "Epoch = 78, loss = 45.34402018785477\n",
      "Epoch = 79, loss = 43.483223646879196\n",
      "Epoch = 80, loss = 43.35786336660385\n",
      "j = 321, Train Acc = 0.6996753246753247, Test Acc = 0.6447368421052632\n",
      "j = 250, Train Acc = 0.6737012987012987, Test Acc = 0.6677631578947368\n",
      "j = 200, Train Acc = 0.5811688311688312, Test Acc = 0.5888157894736842\n",
      "Epoch = 81, loss = 42.67423698306084\n",
      "Epoch = 82, loss = 44.02965086698532\n",
      "Epoch = 83, loss = 45.104506701231\n",
      "Epoch = 84, loss = 44.345639795064926\n",
      "Epoch = 85, loss = 42.56562113761902\n",
      "Epoch = 86, loss = 44.38681063055992\n",
      "Epoch = 87, loss = 42.4426474571228\n",
      "Epoch = 88, loss = 42.51305794715881\n",
      "Epoch = 89, loss = 42.49497437477112\n",
      "Epoch = 90, loss = 41.53473201394081\n",
      "j = 321, Train Acc = 0.734577922077922, Test Acc = 0.6842105263157895\n",
      "j = 250, Train Acc = 0.674512987012987, Test Acc = 0.6611842105263158\n",
      "j = 200, Train Acc = 0.5827922077922078, Test Acc = 0.5822368421052632\n",
      "Epoch = 91, loss = 48.14216786623001\n",
      "Epoch = 92, loss = 44.531731486320496\n",
      "Epoch = 93, loss = 42.81121647357941\n",
      "Epoch = 94, loss = 41.625970005989075\n",
      "Epoch = 95, loss = 43.14987415075302\n",
      "Epoch = 96, loss = 47.86136090755463\n",
      "Epoch = 97, loss = 44.92207399010658\n",
      "Epoch = 98, loss = 45.01562786102295\n",
      "Epoch = 99, loss = 43.71709689497948\n",
      "Epoch = 100, loss = 43.65487813949585\n",
      "j = 321, Train Acc = 0.7021103896103896, Test Acc = 0.6381578947368421\n",
      "j = 250, Train Acc = 0.6314935064935064, Test Acc = 0.6875\n",
      "j = 200, Train Acc = 0.5738636363636364, Test Acc = 0.569078947368421\n",
      "Epoch = 101, loss = 46.84740376472473\n",
      "Epoch = 102, loss = 43.12824550271034\n",
      "Epoch = 103, loss = 42.66895914077759\n",
      "Epoch = 104, loss = 42.247379034757614\n",
      "Epoch = 105, loss = 42.11886686086655\n",
      "Epoch = 106, loss = 42.36689159274101\n",
      "Epoch = 107, loss = 42.14969474077225\n",
      "Epoch = 108, loss = 41.919789880514145\n",
      "Epoch = 109, loss = 42.12308743596077\n",
      "Epoch = 110, loss = 40.7471439242363\n",
      "j = 321, Train Acc = 0.7751623376623377, Test Acc = 0.7302631578947368\n",
      "j = 250, Train Acc = 0.6469155844155844, Test Acc = 0.7006578947368421\n",
      "j = 200, Train Acc = 0.5852272727272727, Test Acc = 0.5822368421052632\n",
      "Epoch = 111, loss = 41.846054166555405\n",
      "Epoch = 112, loss = 40.974627166986465\n",
      "Epoch = 113, loss = 40.84632897377014\n",
      "Epoch = 114, loss = 41.03423058986664\n",
      "Epoch = 115, loss = 40.72087535262108\n",
      "Epoch = 116, loss = 41.30320164561272\n",
      "Epoch = 117, loss = 41.02120280265808\n",
      "Epoch = 118, loss = 40.89640086889267\n",
      "Epoch = 119, loss = 41.05743783712387\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "\n",
    "\n",
    "# train iterations\n",
    "for epoch in range(61,120):\n",
    "    epoch_loss=0\n",
    "    X_train = X_train_generator(innings2_train)\n",
    "    num_batches = X_train.size(0) // batch_size\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        model.zero_grad()\n",
    "        op = model(X_train[start_idx:end_idx])\n",
    "        loss = loss_function(op.contiguous().view(-1,outsize), y_train[start_idx:end_idx].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss+=loss.data.item()\n",
    "        optimizer.step()\n",
    "    print('Epoch = {}, loss = {}'.format(epoch,epoch_loss))\n",
    "    if epoch%10==0:\n",
    "        for j in [321,250,200]:\n",
    "            evalfunc(model,j)\n",
    "\n",
    "torch.save(model.state_dict(), './models/cric_prediction_M1B1_randomsample.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 121, loss = 40.30392572283745\n",
      "Epoch = 122, loss = 40.647254556417465\n",
      "Epoch = 123, loss = 40.238804042339325\n",
      "Epoch = 124, loss = 41.13992765545845\n",
      "Epoch = 125, loss = 40.291603058576584\n",
      "Epoch = 126, loss = 40.16562223434448\n",
      "Epoch = 127, loss = 40.237551778554916\n",
      "Epoch = 128, loss = 40.17660480737686\n",
      "Epoch = 129, loss = 40.281757324934006\n",
      "Epoch = 130, loss = 40.34495559334755\n",
      "j = 321, Train Acc = 0.7581168831168831, Test Acc = 0.7105263157894737\n",
      "j = 250, Train Acc = 0.6761363636363636, Test Acc = 0.7039473684210527\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5888157894736842\n",
      "Epoch = 131, loss = 40.010081112384796\n",
      "Epoch = 132, loss = 39.88279302418232\n",
      "Epoch = 133, loss = 40.121012419462204\n",
      "Epoch = 134, loss = 39.97076407074928\n",
      "Epoch = 135, loss = 40.77816781401634\n",
      "Epoch = 136, loss = 40.50542455911636\n",
      "Epoch = 137, loss = 41.0333736538887\n",
      "Epoch = 138, loss = 52.5030038356781\n",
      "Epoch = 139, loss = 52.60395222902298\n",
      "Epoch = 140, loss = 52.508822202682495\n",
      "j = 321, Train Acc = 0.5698051948051948, Test Acc = 0.4967105263157895\n",
      "j = 250, Train Acc = 0.5706168831168831, Test Acc = 0.4967105263157895\n",
      "j = 200, Train Acc = 0.5032467532467533, Test Acc = 0.5164473684210527\n",
      "Epoch = 141, loss = 52.309851586818695\n",
      "Epoch = 142, loss = 52.40260285139084\n",
      "Epoch = 143, loss = 52.416487991809845\n",
      "Epoch = 144, loss = 52.31308561563492\n",
      "Epoch = 145, loss = 52.33189272880554\n",
      "Epoch = 146, loss = 52.250529050827026\n",
      "Epoch = 147, loss = 52.02012950181961\n",
      "Epoch = 148, loss = 52.417882800102234\n",
      "Epoch = 149, loss = 52.23482686281204\n",
      "Epoch = 150, loss = 51.86375969648361\n",
      "j = 321, Train Acc = 0.5795454545454546, Test Acc = 0.5032894736842105\n",
      "j = 250, Train Acc = 0.5795454545454546, Test Acc = 0.5032894736842105\n",
      "j = 200, Train Acc = 0.5064935064935064, Test Acc = 0.5230263157894737\n",
      "Epoch = 151, loss = 52.26770442724228\n",
      "Epoch = 152, loss = 51.81108146905899\n",
      "Epoch = 153, loss = 52.18278360366821\n",
      "Epoch = 154, loss = 51.80481553077698\n",
      "Epoch = 155, loss = 51.40820270776749\n",
      "Epoch = 156, loss = 51.83833283185959\n",
      "Epoch = 157, loss = 51.12819081544876\n",
      "Epoch = 158, loss = 51.30237776041031\n",
      "Epoch = 159, loss = 50.84456151723862\n",
      "Epoch = 160, loss = 50.49242579936981\n",
      "j = 321, Train Acc = 0.6371753246753247, Test Acc = 0.5953947368421053\n",
      "j = 250, Train Acc = 0.6314935064935064, Test Acc = 0.6217105263157895\n",
      "j = 200, Train Acc = 0.5097402597402597, Test Acc = 0.5164473684210527\n",
      "Epoch = 161, loss = 49.7695817053318\n",
      "Epoch = 162, loss = 49.834252536296844\n",
      "Epoch = 163, loss = 46.32561442255974\n",
      "Epoch = 164, loss = 43.67874225974083\n",
      "Epoch = 165, loss = 44.97436136007309\n",
      "Epoch = 166, loss = 47.993644028902054\n",
      "Epoch = 167, loss = 47.98678547143936\n",
      "Epoch = 168, loss = 43.475855112075806\n",
      "Epoch = 169, loss = 42.27853745222092\n",
      "Epoch = 170, loss = 41.33053079247475\n",
      "j = 321, Train Acc = 0.7597402597402597, Test Acc = 0.7203947368421053\n",
      "j = 250, Train Acc = 0.6493506493506493, Test Acc = 0.7105263157894737\n",
      "j = 200, Train Acc = 0.5925324675324676, Test Acc = 0.5953947368421053\n",
      "Epoch = 171, loss = 40.151133090257645\n",
      "Epoch = 172, loss = 40.65515398979187\n",
      "Epoch = 173, loss = 41.11028552055359\n",
      "Epoch = 174, loss = 41.196473866701126\n",
      "Epoch = 175, loss = 41.688183814287186\n",
      "Epoch = 176, loss = 40.328894942998886\n",
      "Epoch = 177, loss = 41.27280402183533\n",
      "Epoch = 178, loss = 40.29919093847275\n",
      "Epoch = 179, loss = 40.07254105806351\n",
      "Epoch = 180, loss = 42.73712331056595\n",
      "j = 321, Train Acc = 0.7532467532467533, Test Acc = 0.7105263157894737\n",
      "j = 250, Train Acc = 0.648538961038961, Test Acc = 0.7105263157894737\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 181, loss = 40.17819342017174\n",
      "Epoch = 182, loss = 41.06357806921005\n",
      "Epoch = 183, loss = 40.41150817275047\n",
      "Epoch = 184, loss = 39.489344239234924\n",
      "Epoch = 185, loss = 40.380763575434685\n",
      "Epoch = 186, loss = 40.192793399095535\n",
      "Epoch = 187, loss = 40.65019465982914\n",
      "Epoch = 188, loss = 40.35905322432518\n",
      "Epoch = 189, loss = 40.00011473894119\n",
      "Epoch = 190, loss = 40.64079603552818\n",
      "j = 321, Train Acc = 0.7329545454545454, Test Acc = 0.6907894736842105\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5888157894736842\n",
      "Epoch = 191, loss = 39.67467615008354\n",
      "Epoch = 192, loss = 39.28791759908199\n",
      "Epoch = 193, loss = 40.13612285256386\n",
      "Epoch = 194, loss = 39.71013626456261\n",
      "Epoch = 195, loss = 39.441078424453735\n",
      "Epoch = 196, loss = 39.70558509230614\n",
      "Epoch = 197, loss = 39.18797034025192\n",
      "Epoch = 198, loss = 39.815077751874924\n",
      "Epoch = 199, loss = 39.8811439871788\n",
      "Epoch = 200, loss = 39.813374519348145\n",
      "j = 321, Train Acc = 0.7621753246753247, Test Acc = 0.7105263157894737\n",
      "j = 250, Train Acc = 0.6574675324675324, Test Acc = 0.7039473684210527\n",
      "j = 200, Train Acc = 0.5900974025974026, Test Acc = 0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "\n",
    "\n",
    "# train iterations\n",
    "for epoch in range(121,201):\n",
    "    epoch_loss=0\n",
    "    X_train = X_train_generator(innings2_train)\n",
    "    num_batches = X_train.size(0) // batch_size\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        model.zero_grad()\n",
    "        op = model(X_train[start_idx:end_idx])\n",
    "        loss = loss_function(op.contiguous().view(-1,outsize), y_train[start_idx:end_idx].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss+=loss.data.item()\n",
    "        optimizer.step()\n",
    "    print('Epoch = {}, loss = {}'.format(epoch,epoch_loss))\n",
    "    if epoch%10==0:\n",
    "        for j in [321,250,200]:\n",
    "            evalfunc(model,j)\n",
    "\n",
    "torch.save(model.state_dict(), './models/cric_prediction_M1B1_randomsample.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 201, loss = 39.4869422018528\n",
      "Epoch = 202, loss = 41.72693482041359\n",
      "Epoch = 203, loss = 39.47155658900738\n",
      "Epoch = 204, loss = 40.056733787059784\n",
      "Epoch = 205, loss = 39.68918797373772\n",
      "Epoch = 206, loss = 39.41008400917053\n",
      "Epoch = 207, loss = 39.27362395823002\n",
      "Epoch = 208, loss = 39.68775573372841\n",
      "Epoch = 209, loss = 39.70422703027725\n",
      "Epoch = 210, loss = 39.538359716534615\n",
      "j = 321, Train Acc = 0.7443181818181818, Test Acc = 0.7006578947368421\n",
      "j = 250, Train Acc = 0.6891233766233766, Test Acc = 0.6743421052631579\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5921052631578947\n",
      "Epoch = 211, loss = 39.29075272381306\n",
      "Epoch = 212, loss = 39.017792761325836\n",
      "Epoch = 213, loss = 40.07129579782486\n",
      "Epoch = 214, loss = 39.80070674419403\n",
      "Epoch = 215, loss = 39.75534808635712\n",
      "Epoch = 216, loss = 39.439828380942345\n",
      "Epoch = 217, loss = 39.74226728081703\n",
      "Epoch = 218, loss = 39.13374847173691\n",
      "Epoch = 219, loss = 39.45093114674091\n",
      "Epoch = 220, loss = 39.17780637741089\n",
      "j = 321, Train Acc = 0.7589285714285714, Test Acc = 0.7138157894736842\n",
      "j = 250, Train Acc = 0.689935064935065, Test Acc = 0.6644736842105263\n",
      "j = 200, Train Acc = 0.5933441558441559, Test Acc = 0.5888157894736842\n",
      "Epoch = 221, loss = 38.948337346315384\n",
      "Epoch = 222, loss = 39.621954053640366\n",
      "Epoch = 223, loss = 39.25550118088722\n",
      "Epoch = 224, loss = 41.12357072532177\n",
      "Epoch = 225, loss = 39.37171895802021\n",
      "Epoch = 226, loss = 39.1357836574316\n",
      "Epoch = 227, loss = 39.0692383646965\n",
      "Epoch = 228, loss = 39.74385493993759\n",
      "Epoch = 229, loss = 40.65755158662796\n",
      "Epoch = 230, loss = 39.6671279668808\n",
      "j = 321, Train Acc = 0.7378246753246753, Test Acc = 0.6973684210526315\n",
      "j = 250, Train Acc = 0.6891233766233766, Test Acc = 0.6644736842105263\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5855263157894737\n",
      "Epoch = 231, loss = 39.26314675807953\n",
      "Epoch = 232, loss = 43.91077242791653\n",
      "Epoch = 233, loss = 51.00029128789902\n",
      "Epoch = 234, loss = 48.24627619981766\n",
      "Epoch = 235, loss = 44.58213582634926\n",
      "Epoch = 236, loss = 43.27312710881233\n",
      "Epoch = 237, loss = 41.91426581144333\n",
      "Epoch = 238, loss = 39.74131375551224\n",
      "Epoch = 239, loss = 39.149286806583405\n",
      "Epoch = 240, loss = 39.373016357421875\n",
      "j = 321, Train Acc = 0.8206168831168831, Test Acc = 0.7828947368421053\n",
      "j = 250, Train Acc = 0.6915584415584416, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5888157894736842\n",
      "Epoch = 241, loss = 39.83766098320484\n",
      "Epoch = 242, loss = 39.12160086631775\n",
      "Epoch = 243, loss = 39.60926243662834\n",
      "Epoch = 244, loss = 39.39811411499977\n",
      "Epoch = 245, loss = 39.79334081709385\n",
      "Epoch = 246, loss = 39.356584548950195\n",
      "Epoch = 247, loss = 39.517173767089844\n",
      "Epoch = 248, loss = 39.41250383853912\n",
      "Epoch = 249, loss = 39.896623224020004\n",
      "Epoch = 250, loss = 39.11673180758953\n",
      "j = 321, Train Acc = 0.7613636363636364, Test Acc = 0.7171052631578947\n",
      "j = 250, Train Acc = 0.6891233766233766, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 251, loss = 39.21069751679897\n",
      "Epoch = 252, loss = 38.901621013879776\n",
      "Epoch = 253, loss = 39.20990753173828\n",
      "Epoch = 254, loss = 40.29628609120846\n",
      "Epoch = 255, loss = 39.45524601638317\n",
      "Epoch = 256, loss = 39.123116344213486\n",
      "Epoch = 257, loss = 39.06249760091305\n",
      "Epoch = 258, loss = 38.96349786221981\n",
      "Epoch = 259, loss = 38.74271596968174\n",
      "Epoch = 260, loss = 39.09372505545616\n",
      "j = 321, Train Acc = 0.7280844155844156, Test Acc = 0.6776315789473685\n",
      "j = 250, Train Acc = 0.6883116883116883, Test Acc = 0.6611842105263158\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5953947368421053\n",
      "Epoch = 261, loss = 38.5615341514349\n",
      "Epoch = 262, loss = 39.13147647678852\n",
      "Epoch = 263, loss = 39.40462625026703\n",
      "Epoch = 264, loss = 39.65871296823025\n",
      "Epoch = 265, loss = 39.15726488828659\n",
      "Epoch = 266, loss = 39.34074667096138\n",
      "Epoch = 267, loss = 39.63658781349659\n",
      "Epoch = 268, loss = 38.957186460494995\n",
      "Epoch = 269, loss = 39.53018981218338\n",
      "Epoch = 270, loss = 39.22277531027794\n",
      "j = 321, Train Acc = 0.7581168831168831, Test Acc = 0.7171052631578947\n",
      "j = 250, Train Acc = 0.6875, Test Acc = 0.6710526315789473\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5921052631578947\n",
      "Epoch = 271, loss = 39.09168468415737\n",
      "Epoch = 272, loss = 38.93451473116875\n",
      "Epoch = 273, loss = 39.170852065086365\n",
      "Epoch = 274, loss = 39.19811847805977\n",
      "Epoch = 275, loss = 39.15802392363548\n",
      "Epoch = 276, loss = 39.02780140936375\n",
      "Epoch = 277, loss = 39.20357525348663\n",
      "Epoch = 278, loss = 38.86008317768574\n",
      "Epoch = 279, loss = 39.450166419148445\n",
      "Epoch = 280, loss = 39.23395122587681\n",
      "j = 321, Train Acc = 0.7362012987012987, Test Acc = 0.6907894736842105\n",
      "j = 250, Train Acc = 0.6875, Test Acc = 0.6677631578947368\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 281, loss = 38.93046943843365\n",
      "Epoch = 282, loss = 39.147838681936264\n",
      "Epoch = 283, loss = 39.11026127636433\n",
      "Epoch = 284, loss = 38.88315835595131\n",
      "Epoch = 285, loss = 38.49125590920448\n",
      "Epoch = 286, loss = 39.22650730609894\n",
      "Epoch = 287, loss = 38.351638585329056\n",
      "Epoch = 288, loss = 38.51592856645584\n",
      "Epoch = 289, loss = 39.43049304187298\n",
      "Epoch = 290, loss = 38.955547124147415\n",
      "j = 321, Train Acc = 0.7564935064935064, Test Acc = 0.7105263157894737\n",
      "j = 250, Train Acc = 0.6939935064935064, Test Acc = 0.6710526315789473\n",
      "j = 200, Train Acc = 0.5925324675324676, Test Acc = 0.5888157894736842\n",
      "Epoch = 291, loss = 39.015270590782166\n",
      "Epoch = 292, loss = 38.66998943686485\n",
      "Epoch = 293, loss = 38.422577261924744\n",
      "Epoch = 294, loss = 38.87318354845047\n",
      "Epoch = 295, loss = 38.51344646513462\n",
      "Epoch = 296, loss = 38.87990257143974\n",
      "Epoch = 297, loss = 38.93570666015148\n",
      "Epoch = 298, loss = 39.04508826136589\n",
      "Epoch = 299, loss = 39.44979265332222\n",
      "Epoch = 300, loss = 38.4863176047802\n",
      "j = 321, Train Acc = 0.747564935064935, Test Acc = 0.7072368421052632\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6743421052631579\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 301, loss = 38.855590894818306\n",
      "Epoch = 302, loss = 38.24419340491295\n",
      "Epoch = 303, loss = 38.90964096784592\n",
      "Epoch = 304, loss = 38.777789294719696\n",
      "Epoch = 305, loss = 37.97300463914871\n",
      "Epoch = 306, loss = 38.74396654963493\n",
      "Epoch = 307, loss = 39.64904513955116\n",
      "Epoch = 308, loss = 38.75767982006073\n",
      "Epoch = 309, loss = 38.895049408078194\n",
      "Epoch = 310, loss = 38.54534727334976\n",
      "j = 321, Train Acc = 0.7702922077922078, Test Acc = 0.7302631578947368\n",
      "j = 250, Train Acc = 0.6858766233766234, Test Acc = 0.6710526315789473\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 311, loss = 38.85322043299675\n",
      "Epoch = 312, loss = 38.21221452951431\n",
      "Epoch = 313, loss = 38.52020788192749\n",
      "Epoch = 314, loss = 39.107625529170036\n",
      "Epoch = 315, loss = 39.776133596897125\n",
      "Epoch = 316, loss = 38.374965995550156\n",
      "Epoch = 317, loss = 38.45805090665817\n",
      "Epoch = 318, loss = 39.22011452913284\n",
      "Epoch = 319, loss = 39.02260307967663\n",
      "Epoch = 320, loss = 38.792408496141434\n",
      "j = 321, Train Acc = 0.7573051948051948, Test Acc = 0.7138157894736842\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 321, loss = 38.51525089144707\n",
      "Epoch = 322, loss = 38.79311449825764\n",
      "Epoch = 323, loss = 38.961988747119904\n",
      "Epoch = 324, loss = 39.04932111501694\n",
      "Epoch = 325, loss = 39.3480681180954\n",
      "Epoch = 326, loss = 38.719225615262985\n",
      "Epoch = 327, loss = 38.55259445309639\n",
      "Epoch = 328, loss = 38.95307096838951\n",
      "Epoch = 329, loss = 38.42478692531586\n",
      "Epoch = 330, loss = 38.43132695555687\n",
      "j = 321, Train Acc = 0.7573051948051948, Test Acc = 0.7171052631578947\n",
      "j = 250, Train Acc = 0.6728896103896104, Test Acc = 0.7039473684210527\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 331, loss = 38.14758664369583\n",
      "Epoch = 332, loss = 38.428007394075394\n",
      "Epoch = 333, loss = 38.677487060427666\n",
      "Epoch = 334, loss = 38.473055467009544\n",
      "Epoch = 335, loss = 38.30061289668083\n",
      "Epoch = 336, loss = 38.44428330659866\n",
      "Epoch = 337, loss = 38.454612120985985\n",
      "Epoch = 338, loss = 38.76028719544411\n",
      "Epoch = 339, loss = 38.836209028959274\n",
      "Epoch = 340, loss = 39.4620726108551\n",
      "j = 321, Train Acc = 0.7426948051948052, Test Acc = 0.6973684210526315\n",
      "j = 250, Train Acc = 0.6883116883116883, Test Acc = 0.680921052631579\n",
      "j = 200, Train Acc = 0.5876623376623377, Test Acc = 0.5921052631578947\n",
      "Epoch = 341, loss = 38.5040747821331\n",
      "Epoch = 342, loss = 38.481397077441216\n",
      "Epoch = 343, loss = 38.66032832860947\n",
      "Epoch = 344, loss = 38.5453575104475\n",
      "Epoch = 345, loss = 38.15017479658127\n",
      "Epoch = 346, loss = 38.58180207014084\n",
      "Epoch = 347, loss = 40.321327060461044\n",
      "Epoch = 348, loss = 38.9947144985199\n",
      "Epoch = 349, loss = 38.90566888451576\n",
      "Epoch = 350, loss = 38.366248577833176\n",
      "j = 321, Train Acc = 0.851461038961039, Test Acc = 0.7927631578947368\n",
      "j = 250, Train Acc = 0.6931818181818182, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 351, loss = 38.73747715353966\n",
      "Epoch = 352, loss = 38.25274050235748\n",
      "Epoch = 353, loss = 38.49902459979057\n",
      "Epoch = 354, loss = 38.304515063762665\n",
      "Epoch = 355, loss = 38.668015733361244\n",
      "Epoch = 356, loss = 38.54063308238983\n",
      "Epoch = 357, loss = 42.03209152817726\n",
      "Epoch = 358, loss = 38.35248947143555\n",
      "Epoch = 359, loss = 39.00682698190212\n",
      "Epoch = 360, loss = 38.65252673625946\n",
      "j = 321, Train Acc = 0.8287337662337663, Test Acc = 0.7796052631578947\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 361, loss = 38.8663509786129\n",
      "Epoch = 362, loss = 39.13253431022167\n",
      "Epoch = 363, loss = 38.23425556719303\n",
      "Epoch = 364, loss = 38.39711135625839\n",
      "Epoch = 365, loss = 38.22657385468483\n",
      "Epoch = 366, loss = 38.42224282026291\n",
      "Epoch = 367, loss = 39.21631681919098\n",
      "Epoch = 368, loss = 38.60069441795349\n",
      "Epoch = 369, loss = 40.40993957221508\n",
      "Epoch = 370, loss = 38.826310098171234\n",
      "j = 321, Train Acc = 0.7637987012987013, Test Acc = 0.7105263157894737\n",
      "j = 250, Train Acc = 0.689935064935065, Test Acc = 0.6644736842105263\n",
      "j = 200, Train Acc = 0.5892857142857143, Test Acc = 0.5723684210526315\n",
      "Epoch = 371, loss = 38.722617372870445\n",
      "Epoch = 372, loss = 39.03113295137882\n",
      "Epoch = 373, loss = 38.35081987082958\n",
      "Epoch = 374, loss = 38.533132433891296\n",
      "Epoch = 375, loss = 38.417384684085846\n",
      "Epoch = 376, loss = 38.10361212491989\n",
      "Epoch = 377, loss = 38.11588706076145\n",
      "Epoch = 378, loss = 41.866625770926476\n",
      "Epoch = 379, loss = 39.429406613111496\n",
      "Epoch = 380, loss = 38.40876096487045\n",
      "j = 321, Train Acc = 0.8084415584415584, Test Acc = 0.7598684210526315\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 381, loss = 38.488568022847176\n",
      "Epoch = 382, loss = 38.28189140558243\n",
      "Epoch = 383, loss = 38.18139471113682\n",
      "Epoch = 384, loss = 38.420669972896576\n",
      "Epoch = 385, loss = 38.57217714190483\n",
      "Epoch = 386, loss = 38.19207265973091\n",
      "Epoch = 387, loss = 39.22341351211071\n",
      "Epoch = 388, loss = 39.81859913468361\n",
      "Epoch = 389, loss = 39.083451092243195\n",
      "Epoch = 390, loss = 39.0577043145895\n",
      "j = 321, Train Acc = 0.8311688311688312, Test Acc = 0.7828947368421053\n",
      "j = 250, Train Acc = 0.689935064935065, Test Acc = 0.6842105263157895\n",
      "j = 200, Train Acc = 0.5868506493506493, Test Acc = 0.5921052631578947\n",
      "Epoch = 391, loss = 39.0363362878561\n",
      "Epoch = 392, loss = 38.942100673913956\n",
      "Epoch = 393, loss = 38.50014171004295\n",
      "Epoch = 394, loss = 38.25404541194439\n",
      "Epoch = 395, loss = 38.617092207074165\n",
      "Epoch = 396, loss = 38.221290707588196\n",
      "Epoch = 397, loss = 38.20131674408913\n",
      "Epoch = 398, loss = 38.17295789718628\n",
      "Epoch = 399, loss = 38.82885779440403\n",
      "Epoch = 400, loss = 38.190646931529045\n",
      "j = 321, Train Acc = 0.8441558441558441, Test Acc = 0.7828947368421053\n",
      "j = 250, Train Acc = 0.6501623376623377, Test Acc = 0.7072368421052632\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5921052631578947\n",
      "Epoch = 401, loss = 38.58569625020027\n",
      "Epoch = 402, loss = 38.29570713639259\n",
      "Epoch = 403, loss = 38.180867061018944\n",
      "Epoch = 404, loss = 38.65777938067913\n",
      "Epoch = 405, loss = 38.2802542001009\n",
      "Epoch = 406, loss = 38.84396293759346\n",
      "Epoch = 407, loss = 38.19569221138954\n",
      "Epoch = 408, loss = 38.70486322045326\n",
      "Epoch = 409, loss = 38.74861876666546\n",
      "Epoch = 410, loss = 38.77945828437805\n",
      "j = 321, Train Acc = 0.8433441558441559, Test Acc = 0.7861842105263158\n",
      "j = 250, Train Acc = 0.6647727272727273, Test Acc = 0.680921052631579\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 411, loss = 39.105286940932274\n",
      "Epoch = 412, loss = 38.591015085577965\n",
      "Epoch = 413, loss = 38.35717345774174\n",
      "Epoch = 414, loss = 37.910143345594406\n",
      "Epoch = 415, loss = 38.25774849951267\n",
      "Epoch = 416, loss = 38.914922550320625\n",
      "Epoch = 417, loss = 38.98815989494324\n",
      "Epoch = 418, loss = 38.770474538207054\n",
      "Epoch = 419, loss = 38.31395202875137\n",
      "Epoch = 420, loss = 38.28740943968296\n",
      "j = 321, Train Acc = 0.7248376623376623, Test Acc = 0.6644736842105263\n",
      "j = 250, Train Acc = 0.6696428571428571, Test Acc = 0.6875\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 421, loss = 37.95487414300442\n",
      "Epoch = 422, loss = 38.27073781192303\n",
      "Epoch = 423, loss = 38.30323266983032\n",
      "Epoch = 424, loss = 38.554909870028496\n",
      "Epoch = 425, loss = 38.134533539414406\n",
      "Epoch = 426, loss = 38.14388583600521\n",
      "Epoch = 427, loss = 38.34688597917557\n",
      "Epoch = 428, loss = 38.33118146657944\n",
      "Epoch = 429, loss = 38.44135597348213\n",
      "Epoch = 430, loss = 38.173899948596954\n",
      "j = 321, Train Acc = 0.8530844155844156, Test Acc = 0.7927631578947368\n",
      "j = 250, Train Acc = 0.6672077922077922, Test Acc = 0.6776315789473685\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5921052631578947\n",
      "Epoch = 431, loss = 38.35240399837494\n",
      "Epoch = 432, loss = 37.9539480805397\n",
      "Epoch = 433, loss = 38.24726903438568\n",
      "Epoch = 434, loss = 38.26876129209995\n",
      "Epoch = 435, loss = 38.144009470939636\n",
      "Epoch = 436, loss = 38.37106128036976\n",
      "Epoch = 437, loss = 38.510467410087585\n",
      "Epoch = 438, loss = 39.5538544356823\n",
      "Epoch = 439, loss = 38.87558716535568\n",
      "Epoch = 440, loss = 39.01072981953621\n",
      "j = 321, Train Acc = 0.827922077922078, Test Acc = 0.7763157894736842\n",
      "j = 250, Train Acc = 0.648538961038961, Test Acc = 0.7072368421052632\n",
      "j = 200, Train Acc = 0.5900974025974026, Test Acc = 0.5855263157894737\n",
      "Epoch = 441, loss = 38.42678847908974\n",
      "Epoch = 442, loss = 38.60691964626312\n",
      "Epoch = 443, loss = 38.48439249396324\n",
      "Epoch = 444, loss = 38.09036506712437\n",
      "Epoch = 445, loss = 38.986785769462585\n",
      "Epoch = 446, loss = 38.5522046983242\n",
      "Epoch = 447, loss = 38.13543784618378\n",
      "Epoch = 448, loss = 38.15839557349682\n",
      "Epoch = 449, loss = 37.95062367618084\n",
      "Epoch = 450, loss = 37.92575132846832\n",
      "j = 321, Train Acc = 0.8287337662337663, Test Acc = 0.7763157894736842\n",
      "j = 250, Train Acc = 0.6923701298701299, Test Acc = 0.6644736842105263\n",
      "j = 200, Train Acc = 0.5917207792207793, Test Acc = 0.5888157894736842\n",
      "Epoch = 451, loss = 37.98810347914696\n",
      "Epoch = 452, loss = 38.06349955499172\n",
      "Epoch = 453, loss = 37.93295270204544\n",
      "Epoch = 454, loss = 38.0423633903265\n",
      "Epoch = 455, loss = 39.16606578230858\n",
      "Epoch = 456, loss = 40.09364579617977\n",
      "Epoch = 457, loss = 38.4167814552784\n",
      "Epoch = 458, loss = 38.68475566804409\n",
      "Epoch = 459, loss = 38.71369281411171\n",
      "Epoch = 460, loss = 39.03059312701225\n",
      "j = 321, Train Acc = 0.8084415584415584, Test Acc = 0.7598684210526315\n",
      "j = 250, Train Acc = 0.6655844155844156, Test Acc = 0.6907894736842105\n",
      "j = 200, Train Acc = 0.5900974025974026, Test Acc = 0.5855263157894737\n",
      "Epoch = 461, loss = 38.42140503227711\n",
      "Epoch = 462, loss = 38.51787078380585\n",
      "Epoch = 463, loss = 39.93893709778786\n",
      "Epoch = 464, loss = 38.75007835030556\n",
      "Epoch = 465, loss = 37.771248042583466\n",
      "Epoch = 466, loss = 37.94061267375946\n",
      "Epoch = 467, loss = 38.29796227812767\n",
      "Epoch = 468, loss = 37.805089831352234\n",
      "Epoch = 469, loss = 38.08727504312992\n",
      "Epoch = 470, loss = 38.25097617506981\n",
      "j = 321, Train Acc = 0.859577922077922, Test Acc = 0.8125\n",
      "j = 250, Train Acc = 0.6907467532467533, Test Acc = 0.6677631578947368\n",
      "j = 200, Train Acc = 0.5909090909090909, Test Acc = 0.5921052631578947\n",
      "Epoch = 471, loss = 37.850891157984734\n",
      "Epoch = 472, loss = 38.44853365421295\n",
      "Epoch = 473, loss = 37.74263480305672\n",
      "Epoch = 474, loss = 37.73711550235748\n",
      "Epoch = 475, loss = 37.62907491624355\n",
      "Epoch = 476, loss = 38.00577536225319\n",
      "Epoch = 477, loss = 37.87806563079357\n",
      "Epoch = 478, loss = 40.06749376654625\n",
      "Epoch = 479, loss = 39.16194173693657\n",
      "Epoch = 480, loss = 38.04304055869579\n",
      "j = 321, Train Acc = 0.8400974025974026, Test Acc = 0.7697368421052632\n",
      "j = 250, Train Acc = 0.698051948051948, Test Acc = 0.6546052631578947\n",
      "j = 200, Train Acc = 0.5949675324675324, Test Acc = 0.5723684210526315\n",
      "Epoch = 481, loss = 38.58919396996498\n",
      "Epoch = 482, loss = 37.91675202548504\n",
      "Epoch = 483, loss = 38.04521881043911\n",
      "Epoch = 484, loss = 37.76597613096237\n",
      "Epoch = 485, loss = 37.340877681970596\n",
      "Epoch = 486, loss = 37.927161157131195\n",
      "Epoch = 487, loss = 38.215397864580154\n",
      "Epoch = 488, loss = 37.46862709522247\n",
      "Epoch = 489, loss = 38.228067338466644\n",
      "Epoch = 490, loss = 37.94328646361828\n",
      "j = 321, Train Acc = 0.8563311688311688, Test Acc = 0.7927631578947368\n",
      "j = 250, Train Acc = 0.6574675324675324, Test Acc = 0.6875\n",
      "j = 200, Train Acc = 0.588474025974026, Test Acc = 0.5657894736842105\n",
      "Epoch = 491, loss = 38.13508304953575\n",
      "Epoch = 492, loss = 38.41609965264797\n",
      "Epoch = 493, loss = 39.20738314092159\n",
      "Epoch = 494, loss = 39.31922885775566\n",
      "Epoch = 495, loss = 37.83986283838749\n",
      "Epoch = 496, loss = 37.64005061984062\n",
      "Epoch = 497, loss = 37.893131121993065\n",
      "Epoch = 498, loss = 39.571982353925705\n",
      "Epoch = 499, loss = 37.92381927371025\n",
      "Epoch = 500, loss = 38.28222352266312\n",
      "j = 321, Train Acc = 0.8482142857142857, Test Acc = 0.7960526315789473\n",
      "j = 250, Train Acc = 0.6907467532467533, Test Acc = 0.6677631578947368\n",
      "j = 200, Train Acc = 0.5876623376623377, Test Acc = 0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "\n",
    "\n",
    "# train iterations\n",
    "for epoch in range(201,501):\n",
    "    epoch_loss=0\n",
    "    X_train = X_train_generator(innings2_train)\n",
    "    num_batches = X_train.size(0) // batch_size\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = (batch_idx+1) * batch_size\n",
    "        model.zero_grad()\n",
    "        op = model(X_train[start_idx:end_idx])\n",
    "        loss = loss_function(op.contiguous().view(-1,outsize), y_train[start_idx:end_idx].view(-1))\n",
    "        loss.backward()\n",
    "        epoch_loss+=loss.data.item()\n",
    "        optimizer.step()\n",
    "    print('Epoch = {}, loss = {}'.format(epoch,epoch_loss))\n",
    "    if epoch%10==0:\n",
    "        for j in [321,250,200]:\n",
    "            evalfunc(model,j)\n",
    "\n",
    "torch.save(model.state_dict(), './models/cric_prediction_M1B1_randomsample.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # This result is for all overs as inputs case\n",
    "# Epoch = 35, loss = 52.047237277030945\n",
    "# Epoch = 36, loss = 52.01414090394974\n",
    "# Epoch = 37, loss = 51.91944259405136\n",
    "# Epoch = 38, loss = 51.50864785909653\n",
    "# Epoch = 39, loss = 28.567791245877743\n",
    "# Epoch = 40, loss = 32.422352373600006\n",
    "# j = 321, Train Acc = 0.8409090909090909, Test Acc = 0.8355263157894737\n",
    "# j = 200, Train Acc = 0.5560064935064936, Test Acc = 0.6052631578947368\n",
    "# j = 100, Train Acc = 0.5194805194805194, Test Acc = 0.5493421052631579\n",
    "# Epoch = 41, loss = 26.737921312451363\n",
    "# Epoch = 42, loss = 23.24614042043686\n",
    "# Epoch = 43, loss = 22.8752434104681\n",
    "# Epoch = 44, loss = 53.03560835123062\n",
    "# Epoch = 45, loss = 47.28141215443611\n",
    "# Epoch = 46, loss = 35.23486316204071\n",
    "# Epoch = 47, loss = 23.303925164043903\n",
    "# Epoch = 48, loss = 22.12454342842102\n",
    "# Epoch = 49, loss = 19.51815900206566\n",
    "# Epoch = 50, loss = 18.069486137479544\n",
    "# j = 321, Train Acc = 0.9204545454545454, Test Acc = 0.9473684210526315\n",
    "# j = 200, Train Acc = 0.5762987012987013, Test Acc = 0.618421052631579\n",
    "# j = 100, Train Acc = 0.5081168831168831, Test Acc = 0.5427631578947368\n",
    "# Epoch = 51, loss = 17.860560324043036\n",
    "# Epoch = 52, loss = 23.788215935230255\n",
    "# Epoch = 53, loss = 20.787461169064045\n",
    "# Epoch = 54, loss = 16.932700466364622\n",
    "# Epoch = 55, loss = 16.28865105099976\n",
    "# Epoch = 56, loss = 16.52232925966382\n",
    "# Epoch = 57, loss = 16.135572612285614\n",
    "# Epoch = 58, loss = 15.656426377594471\n",
    "# Epoch = 59, loss = 15.42301008477807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest]",
   "language": "python",
   "name": "conda-env-pytorch_latest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
